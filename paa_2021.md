# Slide 1: Title
_Presentation given at the [Population Association of America (PAA) Annual Meeting 2021](https://www.populationassociation.org/paa-2021/home)._

Hello, my name is Chuchu Wei from the University of Massachusetts Amherst. Iâ€™ll be presenting this joint work with [Leontine Alkema](https://leontinealkema.github.io/alkema_lab/). In this study, we try to answer the question of population proportion estimation with data being subject to potential misclassification error.

# Slide 2: Introduction

Our motivating question is how to estimate contraceptive prevalence (CP) for all countries in the world using self-reported usage data from national level surveys like demographic health surveys (DHS).

We has proposed a Bayesian model vcalled the family planning estimation model to estimate prevalence in all countries.

Here are two examples of observed self-reported usage of modern contraception over time in Ghana and Nepal, two countries at different stages of their contraceptive transition.

<!-- Here are two examples of observed self-reported usage of modern contraception over time in Burundi and Colombia, two countries at different stages of their contraceptive transition. -->

The estimates from FPEM are added to the country plots, with solid lines referring to point estimates and dashed lines to 80% credible intervals.

# Slide 3: How is the data used in FPEM?

In FPEM, we distinguish between a process model and a data model. A process model is used to describe true prevalence and how it changes with time and allows for estimation and projections to years without data. In this talk, I will focus on the data model that describes how data related to true prevalence.

Let $y$ refer to observed mCPR and $\theta$ to the unknown true mCPR, we assume that the logit-transformed $y$'s are normally distributed with mean equals to logit-transformed $\theta$, and a variance that is the sum of sampling variance $\text{logit}.s^2$, and a non-sampling variance $\tau^2$. 

This data model is motivated by the fact that observed $y$ are obtained in a survey and thus subject to sampling error, and an typical assumption that data are subject to additional non-sampling error. No info of non-sampling error was available at the time FPEM was developed, hence NSE was estimated around 10% for mCPR.

The graph on the right is the relationship between observed $y$ and estimates of $\theta$ based on the data model. We present this relationship as the Bayesian estimates when assuming a uniform prior $U(0,1)$ on $\theta$. So assuming any value for $\theta$ is equally likely.

In this graph of the data model assumption, non-sampling errors are assumed to increase uncertainty when prevalence is close to 0.5 but decrease to zero as prevalence is close to 0 or 1.

Is this kind of relationship reasonable? To assess that question, we considered external data on non-sampling errors in self-reported usage.

# Slide 4: What if we observed some non-sampling error?

In the previous slide, we have shown that there is no particular assumption of the non-sampling error $\tau$ in the current data model.  However, what if we have some evidence of the non-sampling error, for example, the non-sampling error in the form of misclassification error? 

There are two studies that collect follow-up data for DHS of Ghana and Nepal. From these two post-survey studies, we summarize the misclassification error in terms of sensitivity and specificity. If no misclassification, both sensitivity and specificity equals to 1. Sensitivity and specificity being less than 1 suggest the existence of non-sampling error.

Then the question is, what is the data model looks like with such evidence of non-sampling error?

# Slide 5: The visualization of assumption based on misclassification

With sensitivity $se$ and specificity $sp$, observed $y$ now has a linear relationship with true prevalence $\theta$. If $se, sp$ are indeed less than 1, $y$ does not equal to $\theta$, and the current assumption of data model in FPEM is violated.

That said, we can write the true data model with this linear relationship between observed $y$ and true prevalence $\theta$ with the misclassification information, and conduct a comparison between this "true relationship" and our current assumption in FPEM as shown in the two figures. 

Comparing to the ones implied by the current FPEM data model, the relationships based on $se, sp$ from Ghana and Nepal studies clearly suggest a mismatch between the two assumptions. In other words, what we currently assume for the non-sampling error conflicts what would be implied by the two studies.

# Slide 6: How to do a better estimation

The conclusion so far is that, first, we have two small studies suggests self-reported mCPR is subject to misclassification. Second, the current data model assumption cannot capture the additional uncertainty implied by the two studies.

The discrepancy indicate an obvious next step to replace the current data model in FPEM with one that explicitly accounts for misclassification. But, we only have two studies for two DHS, which means we only have 2 available misclassification data points. Such limited misclassification information is not sufficient for a bias adjustment to over 300 DHS data points used for FPEM.

Here the choice left for us is to update the data model to better reflect uncertainty associated with potential misclassification errors.

# Slide 7: Our proposal: a new data model

To conduct a proper update of the data model in FPEM, we formulate our aims based on the assumption sensitivity $se^a$ and specificity $sp^a$. First, we let the estimate of the true prevalence $\hat\theta$ equals to observed $y$. Second, the 95% CI of $\theta$ is determined by sampling error $s$ if no misclassification. Lastly, the 95% CI of $\theta$ is jointly determined by $s$, assumed sensitivity $se^a$, and assumed specificity $sp^a$.

We find a special distribution to accomplish the aims: the Normal-Laplace (NL) distribution. It is a four-parameter distribution from the convolution of Normal and Laplace distribution. We utilize the NL density as the standardized likelihood of $\theta$ as the new data model, and fixed the four parameters to meet our aims.

The right graphs shows two examples of NL distribution. 

# Slide 8: The visualization of the new data model
# Slide 9: 
# Slide 10: 
# Slide 11: 